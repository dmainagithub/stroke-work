{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da9d05f-82e3-426b-a899-d80c3ee1f347",
   "metadata": {},
   "source": [
    "## Stroke Work\n",
    "<br>Author: Daniel Maina Nderitu<br>\n",
    "Project: MADIVA<br>\n",
    "Purpose: Publication-quality outputs<br>\n",
    "Notes:   To rerun this whenever reviewers ask for tweaks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b540cb14-0b3b-4faa-906d-f4a21bf344f8",
   "metadata": {},
   "source": [
    "#### Bootstrap cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "730f9caa-89b6-4810-86ac-706eec7231e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: D:\\APHRC\\GoogleDrive_ii\\stata_do_files\\madiva\\stroke_work\n",
      "DATA_DIR: D:\\APHRC\\GoogleDrive_ii\\stata_do_files\\madiva\\stroke_work\\data\n",
      "OUT_DIR: D:\\APHRC\\GoogleDrive_ii\\stata_do_files\\madiva\\stroke_work\\model_output\n",
      "FIG_DIR: D:\\APHRC\\GoogleDrive_ii\\stata_do_files\\madiva\\stroke_work\\visualization\n"
     ]
    }
   ],
   "source": [
    "# =================== BOOTSTRAP CELL ===================\n",
    "# Standard setup for all notebooks\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parents[0]  # assumes notebooks are in a subfolder\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# ========================================================\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.config.variables import COVARIATES\n",
    "\n",
    "# ========================================================\n",
    "# Optional for warnings and nicer plots\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ========================================================\n",
    "# 1️⃣ Ensure project root is in Python path\n",
    "# Adjust this if your notebooks are nested deeper\n",
    "PROJECT_ROOT = Path.cwd().parents[0]  # assumes notebooks are in a subfolder\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# ========================================================\n",
    "# 2️⃣ Import helper to load paths\n",
    "from src.utils.helpers import load_paths\n",
    "\n",
    "# ========================================================\n",
    "# 3️⃣ Load paths from config.yaml (works regardless of notebook location)\n",
    "paths = load_paths()\n",
    "\n",
    "# ========================================================\n",
    "# 4️⃣ Optionally, print paths to confirm\n",
    "for key, value in paths.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# ========================================================\n",
    "# 5️⃣ Now you can use these paths in your notebook:\n",
    "# Example:\n",
    "DATA_DIR = paths['DATA_DIR']\n",
    "OUT_DIR = paths['OUT_DIR']\n",
    "FIG_DIR = paths['FIG_DIR']\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a1eef6-ba2a-4507-beb2-4df5f088d58b",
   "metadata": {},
   "source": [
    "### Import data - from previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9398912e-65fe-4f0e-8d55-3e28ff49c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data saved as pickle:\n",
    "df = pd.read_pickle(OUT_DIR / \"df_step03_processed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31442adc-0014-4490-8b2d-9eef422d9d06",
   "metadata": {},
   "source": [
    "#### Forest plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c16b47-37fa-4393-8263-91e4a03a85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =================================================================================  \n",
    "# Ensure sorting by study start\n",
    "# =================================================================================  \n",
    "study_periods_sorted = study_periods.sort_values(\"study_start\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, row in study_periods_sorted.iterrows():\n",
    "    plt.plot([row['study_start'], row['study_end']], \n",
    "             [i, i], linewidth=6)\n",
    "    plt.text(row['study_start'], i+0.1, str(row['source']), fontsize=10)\n",
    "\n",
    "plt.yticks([])\n",
    "plt.xlabel(\"Calendar Time\")\n",
    "plt.title(\"Study Periods by Project (source)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# =================================================================================  \n",
    "\n",
    "# =================================================================================  \n",
    "plt.savefig(FIG_DIR / \"study_periods_graph_main.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# =================================================================================  \n",
    "\n",
    "# =================================================================================  \n",
    "plt.show()\n",
    "# plt.savefig(\"figure_name.png\", dpi=300, bbox_inches='tight')\n",
    "# plt.savefig(\"figure_name.pdf\", bbox_inches='tight')   # optional\n",
    "# plt.savefig(\"figure_name.svg\", bbox_inches='tight')   # optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e390eaa-e527-40bb-aa9a-d02bbaf81b2b",
   "metadata": {},
   "source": [
    "#### Timeline plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a853ec56-2cc3-4e46-ac2a-d30bab56d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique IDs\n",
    "unique_ids = df['individual_id'].drop_duplicates()\n",
    "\n",
    "# Adjust sample size to the number of available individuals\n",
    "sample_size = min(12, len(unique_ids))\n",
    "\n",
    "# Take sample safely\n",
    "sample_ids = unique_ids.sample(sample_size, random_state=42)\n",
    "\n",
    "# Filter dataset for those individuals\n",
    "df_sample = df[df['individual_id'].isin(sample_ids)]\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Create timeline visualization\n",
    "fig = px.timeline(\n",
    "    df_sample,\n",
    "    x_start=\"start_date\",\n",
    "    x_end=\"end_date\",\n",
    "    y=\"individual_id\",\n",
    "    color=\"event\",\n",
    "    color_discrete_map={0: \"skyblue\", 1: \"red\"},\n",
    "    title=\"Observation Timelines with Stroke Events\",\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_yaxes(title=\"Individual ID\", categoryorder=\"total ascending\")\n",
    "fig.update_xaxes(title=\"Date\")\n",
    "fig.update_layout(\n",
    "    legend_title_text=\"Stroke Event (1=Yes, 0=No)\",\n",
    "    template=\"plotly_white\",\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "# Save (Plotly)\n",
    "fig.write_image(\n",
    "    FIG_DIR / \"observation_timelines_Agincourt_Nairobi.png\",\n",
    "    scale=3  # improves resolution for presentations\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998880fe-50e1-4e79-b040-e0d4ffc347c2",
   "metadata": {},
   "source": [
    "#### Annotated figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f595f8-d140-443a-9373-ef32ac3c6ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- prepare a base variable order (use Poisson result as reference) ---\n",
    "varlist = results_pois.loc[results_pois[\"Variable\"] != \"const\", \"Variable\"].tolist()\n",
    "n_vars = len(varlist)\n",
    "base_y = np.arange(n_vars)\n",
    "\n",
    "# vertical offsets so the 3 model points don't overlap\n",
    "y_offsets = {\n",
    "    'Poisson': -0.18,\n",
    "    'Robust Poisson': 0.0,\n",
    "    'NegBinomial': 0.18\n",
    "}\n",
    "\n",
    "colors = {\n",
    "    'Poisson': '#1f77b4',\n",
    "    'Robust Poisson': '#ff7f0e',\n",
    "    'NegBinomial': '#2ca02c'\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# loop over models and plot\n",
    "for model_name, df_irr in [\n",
    "    ('Poisson', results_pois),\n",
    "    ('Robust Poisson', results_robust),\n",
    "    ('NegBinomial', results_nb)\n",
    "]:\n",
    "    # align to varlist so positions are consistent\n",
    "    df_aligned = df_irr.set_index('Variable').reindex(varlist).reset_index()\n",
    "\n",
    "    for j, row in df_aligned.iterrows():\n",
    "        # skip variables with missing estimates\n",
    "        if pd.isna(row['IRR']):\n",
    "            continue\n",
    "\n",
    "        y = base_y[j] + y_offsets[model_name]\n",
    "\n",
    "        # compute left/right error for errorbar\n",
    "        left = row['IRR'] - row['IRR_CI_lower']\n",
    "        right = row['IRR_CI_upper'] - row['IRR']\n",
    "\n",
    "        # Plot errorbar and point\n",
    "        plt.errorbar(\n",
    "            x=row['IRR'],\n",
    "            y=y,\n",
    "            xerr=np.array([[left], [right]]),\n",
    "            fmt='o',\n",
    "            capsize=4,\n",
    "            color=colors[model_name],\n",
    "            label=None  # legend handled below\n",
    "        )\n",
    "\n",
    "        # Add IRR text + significance star to the right of the point\n",
    "        text_offset = 0.03 * (plt.xlim()[1] - plt.xlim()[0]) if plt.xlim()[1] > plt.xlim()[0] else 0.05\n",
    "        # to avoid referencing plt.xlim() before any points are drawn, use a small constant fallback:\n",
    "        if text_offset == 0:\n",
    "            text_offset = 0.05\n",
    "        plt.text(row['IRR'] + text_offset, y, f'{row[\"IRR\"]:.2f}{row.get(\"sig\",\"\")}',\n",
    "                 fontsize=9, color=colors[model_name], va='center')\n",
    "\n",
    "# Add a manual legend (one marker per model)\n",
    "for mn, color in colors.items():\n",
    "    plt.plot([], [], 'o', color=color, label=mn)\n",
    "plt.legend(title='Model')\n",
    "\n",
    "# y-ticks and labels\n",
    "plt.yticks(base_y, varlist)\n",
    "plt.axvline(1, color='red', linestyle='--')\n",
    "plt.xlabel(\"Incidence Rate Ratio (IRR)\")\n",
    "plt.title(\"Stroke Incidence – Model Comparison (IRR with 95% CI)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and show\n",
    "plt.savefig(FIG_DIR / 'stroke_model_comparison_annotated_fixed_main.png', dpi=300)\n",
    "\n",
    "plt.show()\n",
    "print(\"Saved: stroke_model_comparison_annotated_fixed_main.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceab072-a190-4035-b9a6-3be6d3690c21",
   "metadata": {},
   "source": [
    "#### Export tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5213e84c-1ea1-491d-8558-bb9aea4e37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================  \n",
    "# Number of times each person is represented\n",
    "# =================================================================================  \n",
    "counts = df['individual_id'].value_counts()          # number of rows per person (index = individual_id)\n",
    "counts_summary = counts.describe()                   # mean, min, max, median, etc.\n",
    "\n",
    "print(\"\\nRecords per individual (summary):\")\n",
    "print(counts_summary)\n",
    "\n",
    "# =================================================================================  \n",
    "# How many individuals have only one record (single-visit)?\n",
    "# =================================================================================  \n",
    "n_single = (counts == 1).sum()\n",
    "pct_single = (n_single / counts.shape[0]) * 100\n",
    "\n",
    "print(f\"\\nIndividuals with a single record: {n_single} ({pct_single:.1f}%)\")\n",
    "\n",
    "# =================================================================================  \n",
    "# Show frequency distribution (top few)\n",
    "# =================================================================================  \n",
    "print(\"\\nTop frequency counts (number of Agincourt persons with X records):\")\n",
    "freq_table = counts.value_counts().sort_index()      # index = number of records, value = # persons\n",
    "print(freq_table.head(20))  # show first 20 rows; increase if needed\n",
    "\n",
    "# # If you want the full distribution dataframe:\n",
    "# freq_df = freq_table.reset_index().rename(columns={'index': 'n_records', 'individual_id': 'n_persons'})\n",
    "\n",
    "# =================================================================================  \n",
    "# Create a clean dataframe version\n",
    "# =================================================================================  \n",
    "freq_df = freq_table.reset_index(name=\"n_persons\")\n",
    "freq_df.columns = ['n_records', 'n_persons']  # rename safely\n",
    "\n",
    "# =================================================================================  \n",
    "# (Optional) If you intend to use months offsets in models:\n",
    "#     prepare X,y, offset using offset_months\n",
    "# =================================================================================  \n",
    "# Example:\n",
    "# offset_for_model = df['offset_months']\n",
    "# y_for_model = df['event']\n",
    "# X_for_model = df[covariates_present]  # after your usual pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a687d-cc0f-4efb-8ab1-0cd20ccbcaaf",
   "metadata": {},
   "source": [
    "#### Grouped IRR plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d693571a-2f1a-4c24-ab7f-afaf28ab0eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Drop rows with missing confidence intervals\n",
    "plot_df = plot_df.dropna(subset=[\"IRR\", \"IRR_CI_lower\", \"IRR_CI_upper\"]).copy()\n",
    "\n",
    "# Define conceptual categories\n",
    "category_map = {\n",
    "    'sex_binary': 'Demographics',\n",
    "    'alcohol_use': 'Lifestyle',\n",
    "    'tobacco_use': 'Lifestyle',\n",
    "    'bmi_category_Normal': 'Lifestyle', \n",
    "    'bmi_category_Overweight': 'Lifestyle', \n",
    "    'bmi_category_Obese': 'Lifestyle',\n",
    "    'obese_status_derived': 'Comorbidities',\n",
    "    'hpt_status_derived': 'Comorbidities',\n",
    "    'diab_status_derived': 'Comorbidities',\n",
    "    'hiv_status_derived': 'Comorbidities',\n",
    "    'tb_status_derived': 'Comorbidities',\n",
    "    'site_Nairobi': 'Site Effect'\n",
    "}\n",
    "\n",
    "# Define category colors\n",
    "category_colors = {\n",
    "    'Demographics': '#1f77b4',   # blue\n",
    "    'Lifestyle': '#ff7f0e',      # orange\n",
    "    'Comorbidities': '#2ca02c',  # green\n",
    "    'Site Effect': '#9467bd'     # purple\n",
    "}\n",
    "\n",
    "# Assign category and color\n",
    "plot_df['Category'] = plot_df['Variable'].map(category_map)\n",
    "plot_df['Color'] = plot_df['Category'].map(category_colors).fillna('#999999')\n",
    "\n",
    "# Sort by category and variable\n",
    "plot_df = plot_df.sort_values(by=['Category', 'Variable'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Compute symmetric error bars\n",
    "xerr = np.array([\n",
    "    plot_df[\"IRR\"] - plot_df[\"IRR_CI_lower\"],\n",
    "    plot_df[\"IRR_CI_upper\"] - plot_df[\"IRR\"]\n",
    "])\n",
    "\n",
    "# --- PLOT ---\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Plot CIs\n",
    "plt.errorbar(\n",
    "    x=plot_df[\"IRR\"],\n",
    "    y=np.arange(len(plot_df)),\n",
    "    xerr=xerr,\n",
    "    fmt='o',\n",
    "    capsize=4,\n",
    "    color='gray',\n",
    "    ecolor='lightgray',\n",
    "    elinewidth=1.2,\n",
    "    zorder=1\n",
    ")\n",
    "\n",
    "# Plot colored points + annotations\n",
    "for idx, (_, row) in enumerate(plot_df.iterrows()):\n",
    "    plt.scatter(row[\"IRR\"], idx, color=row[\"Color\"], s=60, zorder=2)\n",
    "    irr_text = f'{row[\"IRR\"]:.2f}'\n",
    "    if \"sig\" in row and isinstance(row[\"sig\"], str):\n",
    "        irr_text += row[\"sig\"]\n",
    "    plt.text(row[\"IRR\"] * 1.05, idx, irr_text, va='center', fontsize=9, color='black')\n",
    "\n",
    "# Reference line\n",
    "plt.axvline(1, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "# Axis and labels\n",
    "plt.yticks(np.arange(len(plot_df)), plot_df[\"Variable\"])\n",
    "plt.xlabel(\"Incidence Rate Ratio (IRR)\")\n",
    "plt.title(\"Negative Binomial Model – Stroke Incidence (Grouped by Category)\")\n",
    "\n",
    "# --- Legend in top-right corner ---\n",
    "handles = [\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label=cat,\n",
    "               markerfacecolor=color, markersize=8)\n",
    "    for cat, color in category_colors.items()\n",
    "]\n",
    "plt.legend(handles=handles, title=\"Category\", loc='upper right',\n",
    "           bbox_to_anchor=(1, 1), frameon=False)\n",
    "# plt.legend(title=\"Effect Direction\", loc=\"upper right\", frameon=True)\n",
    "\n",
    "# Layout and aesthetics\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and show\n",
    "output_path = (\n",
    "    FIG_DIR / 'stroke_model_nb_grouped_main.png'\n",
    ")\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✅ Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f546146-7ae5-43d5-a0d2-aa972154f0a1",
   "metadata": {},
   "source": [
    "#### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b01ca10-7a9e-42af-a6b1-c04353fd6cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved as pickle (faster for large data, preserves types)\n",
    "df.to_pickle(OUT_DIR / \"df_step04_processed.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
