{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da9d05f-82e3-426b-a899-d80c3ee1f347",
   "metadata": {},
   "source": [
    "## Stroke Work\n",
    "<br>Author: Daniel Maina Nderitu<br>\n",
    "Project: MADIVA\n",
    "Purpose: Make analysis-ready covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e8465e-df1c-43da-a374-acea40ca9054",
   "metadata": {},
   "source": [
    "#### Bootstrap cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a4cb71-4d64-4eb6-9822-bc278a6ede23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: D:\\APHRC\\GoogleDrive_ii\\stata_do_files\\madiva\\stroke_work\n",
      "DATA_DIR: D:\\APHRC\\GoogleDrive_ii\\stata_do_files\\madiva\\stroke_work\\data\n",
      "OUT_DIR: D:\\APHRC\\GoogleDrive_ii\\stata_do_files\\madiva\\stroke_work\\model_output\n",
      "FIG_DIR: D:\\APHRC\\GoogleDrive_ii\\stata_do_files\\madiva\\stroke_work\\visualization\n",
      "MODEL_DIR: D:\\APHRC\\GoogleDrive_ii\\stata_do_files\\madiva\\stroke_work\\model_output\\statsmodels\n",
      "NOTEBOOKS_DIR: D:\\APHRC\\GoogleDrive_ii\\stata_do_files\\madiva\\stroke_work\\notebooks\n",
      "NOTEBOOKS_EXECUTED_DIR: D:\\APHRC\\GoogleDrive_ii\\stata_do_files\\madiva\\stroke_work\\notebooks_executed\n"
     ]
    }
   ],
   "source": [
    "# =================== BOOTSTRAP CELL ===================\n",
    "# Standard setup for all notebooks\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parents[0]  # assumes notebooks are in a subfolder\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# ========================================================\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.config.variables import COVARIATES\n",
    "from src.config.variables import KEY_PREDICTORS\n",
    "\n",
    "# ========================================================\n",
    "# Optional for warnings and nicer plots\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ========================================================\n",
    "# 1️⃣ Ensure project root is in Python path\n",
    "# Adjust this if your notebooks are nested deeper\n",
    "PROJECT_ROOT = Path.cwd().parents[0]  # assumes notebooks are in a subfolder\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# ========================================================\n",
    "# 2️⃣ Import helper to load paths\n",
    "from src.utils.helpers import load_paths\n",
    "\n",
    "# ========================================================\n",
    "# 3️⃣ Load paths from config.yaml (works regardless of notebook location)\n",
    "paths = load_paths()\n",
    "\n",
    "# ========================================================\n",
    "# 4️⃣ Optionally, print paths to confirm\n",
    "for key, value in paths.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# ========================================================\n",
    "# 5️⃣ Now you can use these paths in your notebook:\n",
    "# Example:\n",
    "DATA_DIR = paths['DATA_DIR']\n",
    "OUT_DIR = paths['OUT_DIR']\n",
    "FIG_DIR = paths['FIG_DIR']\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e321cff-9a99-424c-8f45-a03ae6890a20",
   "metadata": {},
   "source": [
    "### Import data - from previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0445dadb-167d-467b-906e-c60e8cd6fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data saved as pickle:\n",
    "df = pd.read_pickle(OUT_DIR / \"df_step02_processed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0ac72-510e-41c0-b77e-bd76735c6c9d",
   "metadata": {},
   "source": [
    "### Data preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dc673c-daca-46a4-9d2f-28e0b70b7782",
   "metadata": {},
   "source": [
    "#### Projects Name Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7df8f3b-ea62-420e-a95a-8cbafcec1f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_map = {\n",
    "    \"SCALEUP Population Baseline\": \"SCALEUP_Pop_Baseline\",\n",
    "    \"Assess Linkages Main\": \"Assess_Linkages_Main\",\n",
    "    \"HAALSI_1\": \"HAALSI_1\",\n",
    "    \"HIV_NCD\": \"HIV_NCD\",\n",
    "    \"AWIGEN_1\": \"AWIGEN_1\",\n",
    "    \"HAALSI_2\": \"HAALSI_2\",\n",
    "    \"Nkateko_1\": \"Nkateko_1\",\n",
    "    \"HAALSI_3\": \"HAALSI_3\",\n",
    "    \"Nkateko_2\": \"Nkateko_2\",\n",
    "    \"ARKStudyPhase_1\": \"ARK_1\",\n",
    "    \"ARKStudyPhase_2\": \"ARK_2\",\n",
    "    \"AWIGEN_2\": \"AWIGEN_2\",\n",
    "    \"SCALEUP Clinic Baseline\": \"SCALEUP_Clinic_Baseline\",\n",
    "    \"Diabetics Baseline\": \"Diabetics_Baseline\",\n",
    "    \"Diabetics Followup\": \"Diabetics_Followup\"\n",
    "}\n",
    "\n",
    "# Rename\n",
    "df['source'] = df['source'].replace(name_map)\n",
    "\n",
    "# Make it categorical\n",
    "df['source'] = df['source'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "810e4034-b878-475a-8e5e-abc6e46472cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Nkateko_1\n",
       "1        ARK_1\n",
       "2        ARK_2\n",
       "3      HIV_NCD\n",
       "4    Nkateko_1\n",
       "Name: source, dtype: category\n",
       "Categories (15, object): ['ARK_1', 'ARK_2', 'AWIGEN_1', 'AWIGEN_2', ..., 'Nkateko_1', 'Nkateko_2', 'SCALEUP_Clinic_Baseline', 'SCALEUP_Pop_Baseline']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730d47e5-0d50-48cb-be0b-23643171734b",
   "metadata": {},
   "source": [
    "#### Record type, Gender, BMI processing, and type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc8f116a-c017-4cac-9df3-13c7d8c2ba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30146, 339)\n",
      "sex\n",
      "2    16391\n",
      "1    13755\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# Drop individuals with only one record\n",
    "# ------------------------------------------------------------------------------------\n",
    "df = df.loc[df['record_type']==2].copy()\n",
    "print(df.shape)\n",
    "print(df.sex.value_counts())\n",
    "df['sex_binary'] = df['sex'].replace({1: 0, 2: 1})  # 0 = male, 1 = female\n",
    "df['bmi_refined'] = pd.to_numeric(df['bmi_refined'], errors='coerce')\n",
    "# ------------------------------------------------------------------------------------\n",
    "# # BMI based on WHO categories\n",
    "# ------------------------------------------------------------------------------------\n",
    "# df['bmi_category'] = pd.cut(df['bmi_refined'], \n",
    "#                             bins=[0, 18.5, 24.9, 29.9, np.inf], \n",
    "#                             labels=['Underweight', 'Normal', 'Overweight', 'Obese'])\n",
    "# Creating only two categories (making it dichotomous)\n",
    "df['bmi_category'] = pd.cut(df['bmi_refined'], \n",
    "                            bins=[0, 24.9, np.inf], \n",
    "                            labels=['Normal_Underweight', 'Overweight_Obese'])\n",
    "\n",
    "df = pd.get_dummies(df, columns=['bmi_category'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec17ba8c-c4b6-4735-a965-1c882e09c970",
   "metadata": {},
   "source": [
    "#### Site & Source/study dummies (ONE-HOT ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b0e541a-fbfd-4fba-9f8d-c7d55324042e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['site_Nairobi']\n",
      "Site dummy variables created: ['site_Nairobi']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# Making sure 'hdss_name' exists and is a string\n",
    "# ------------------------------------------------------------------------------------\n",
    "df['hdss_name'] = df['hdss_name'].astype(str)\n",
    "\n",
    "# ------------------------------------------------------------------------------------\n",
    "# # Study\n",
    "# ------------------------------------------------------------------------------------\n",
    "# df['source'] = df['source'].astype('category')\n",
    "# df = pd.get_dummies(df, columns=['source'], drop_first=True)\n",
    " \n",
    "# One-hot encode site (drop one to avoid multicollinearity) - Agincourt reference\n",
    "site_dummies = pd.get_dummies(df['hdss_name'], prefix='site', drop_first=True)\n",
    "print(site_dummies.columns.tolist())\n",
    "\n",
    "# If both created, drop 'site_Agincourt' to make it reference\n",
    "if 'site_Nairobi' in site_dummies.columns:\n",
    "    if 'site_Agincourt' not in site_dummies.columns:\n",
    "        # make sure Nairobi present; handle gracefully if not\n",
    "        pass\n",
    "    site_cols = [c for c in site_dummies.columns if c != 'site_Nairobi']\n",
    "else:\n",
    "    site_cols = [c for c in site_dummies.columns]  # in case naming differs\n",
    "\n",
    "# Merge dummy columns into df\n",
    "df = pd.concat([df, site_dummies], axis=1)\n",
    "# df['site_Nairobi'] = df['site_Nairobi'].astype('category')\n",
    "# df['site_Agincourt'] = df['site_Agincourt'].astype('category')\n",
    "\n",
    "\n",
    "print(\"Site dummy variables created:\", list(site_dummies.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e29c0ed-a630-4a9b-bd15-1a722af64273",
   "metadata": {},
   "source": [
    "#### Boolean conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f906c2-6915-4bfc-a5a1-6a75bb2e108f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex_binary\n",
      "1    16391\n",
      "0    13755\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# Convert all boolean columns to integers (0/1)\n",
    "# ------------------------------------------------------------------------------------\n",
    "df = df.astype({col: int for col in df.select_dtypes(bool).columns})\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "print(df.sex_binary.value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55765bfa-44ae-45ba-808c-77c2bb397c21",
   "metadata": {},
   "source": [
    "#### Integer conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "983f3f7b-da16-4377-8c96-f57669e7b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# Converts to integer type\n",
    "# ------------------------------------------------------------------------------------\n",
    "df.bmi_category_Overweight_Obese = df.bmi_category_Overweight_Obese.astype(int)\n",
    "df['site_Nairobi'] = df['site_Nairobi'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09b757f-916a-4562-8c71-0994f1c4bdf8",
   "metadata": {},
   "source": [
    "#### Date conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f58a65d5-937e-4fc6-82e4-d99ddd6cabdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# Convert obs_date from string (e.g., '26jul2008') to datetime\n",
    "# ------------------------------------------------------------------------------------\n",
    "df['obs_date'] = pd.to_datetime(df['obs_date'], format='%d%b%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9d841a-ca72-442c-bca2-4b679f06df66",
   "metadata": {},
   "source": [
    "#### Study Periods—Start and End for Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd5fcea0-8f8e-4a26-b575-ed695bd26dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get study start and end per project (source)\n",
    "study_periods = (\n",
    "    df.groupby('source', observed=True)['obs_date']\n",
    "      .agg(study_start='min', study_end='max')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# 2. Merge study periods back to original data\n",
    "df = df.merge(study_periods, on='source', how='left')\n",
    "\n",
    "# Create dummy variables (one-hot encode)\n",
    "df = pd.get_dummies(df, columns=['source'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ab852d7-a7ba-40c9-8058-c82bed3e0b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individual_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>hdss_name</th>\n",
       "      <th>alco_ever</th>\n",
       "      <th>alco_12m</th>\n",
       "      <th>alco_30d</th>\n",
       "      <th>alco_bing_y</th>\n",
       "      <th>tobac_ever</th>\n",
       "      <th>tobac_cur</th>\n",
       "      <th>...</th>\n",
       "      <th>source_Diabetics_Baseline</th>\n",
       "      <th>source_Diabetics_Followup</th>\n",
       "      <th>source_HAALSI_1</th>\n",
       "      <th>source_HAALSI_2</th>\n",
       "      <th>source_HAALSI_3</th>\n",
       "      <th>source_HIV_NCD</th>\n",
       "      <th>source_Nkateko_1</th>\n",
       "      <th>source_Nkateko_2</th>\n",
       "      <th>source_SCALEUP_Clinic_Baseline</th>\n",
       "      <th>source_SCALEUP_Pop_Baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBBHY</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>Agincourt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBBHY</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>Agincourt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BBBNE</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>Agincourt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BBBNE</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>Agincourt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BBBNE</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>Agincourt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 357 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  individual_id  age  sex  hdss_name  alco_ever  alco_12m  alco_30d  \\\n",
       "0         BBBHY   33    2  Agincourt        NaN       NaN       NaN   \n",
       "1         BBBHY   34    2  Agincourt        NaN       NaN       NaN   \n",
       "2         BBBNE   46    1  Agincourt        1.0       1.0       1.0   \n",
       "3         BBBNE   49    1  Agincourt        NaN       NaN       NaN   \n",
       "4         BBBNE   50    1  Agincourt        1.0       NaN       1.0   \n",
       "\n",
       "   alco_bing_y  tobac_ever  tobac_cur  ...  source_Diabetics_Baseline  \\\n",
       "0          NaN         0.0      888.0  ...                      False   \n",
       "1          NaN       999.0        NaN  ...                      False   \n",
       "2          NaN         1.0        0.0  ...                      False   \n",
       "3          NaN         1.0        0.0  ...                      False   \n",
       "4          1.0         1.0        0.0  ...                      False   \n",
       "\n",
       "   source_Diabetics_Followup  source_HAALSI_1  source_HAALSI_2  \\\n",
       "0                      False            False            False   \n",
       "1                      False            False            False   \n",
       "2                      False            False            False   \n",
       "3                      False            False            False   \n",
       "4                      False             True            False   \n",
       "\n",
       "   source_HAALSI_3  source_HIV_NCD  source_Nkateko_1  source_Nkateko_2  \\\n",
       "0            False           False             False             False   \n",
       "1            False           False             False             False   \n",
       "2            False            True             False             False   \n",
       "3            False           False              True             False   \n",
       "4            False           False             False             False   \n",
       "\n",
       "   source_SCALEUP_Clinic_Baseline  source_SCALEUP_Pop_Baseline  \n",
       "0                           False                        False  \n",
       "1                           False                        False  \n",
       "2                           False                        False  \n",
       "3                           False                        False  \n",
       "4                           False                        False  \n",
       "\n",
       "[5 rows x 357 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb7ba3-4be4-4f54-91a8-0fc96276650c",
   "metadata": {},
   "source": [
    "#### Covariates list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28659ee9-8fb2-46ea-8791-b71c5e9454b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30146, 357)\n"
     ]
    }
   ],
   "source": [
    "# covariates = ['sex_binary', 'alcohol_use', 'tobacco_use', 'hpt_status_derived', 'diab_status_derived','bmi_category_Overweight_Obese'\n",
    "#                ,'hiv_status_derived', 'site_Nairobi'] #  + list(site_dummies.columns) \n",
    "# ,'obese_status_derived' # alot of missingness\n",
    "# tb_status_derived # alot of missingness\n",
    "# , 'res_hha_wealthtertile_2.0', 'res_hha_wealthtertile_3.0'  # (Will add these once we obtain these data points)\n",
    "# ,'bmi_category_Normal', 'bmi_category_Overweight', 'bmi_category_Obese'\n",
    "# print(df.offset.describe())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998880fe-50e1-4e79-b040-e0d4ffc347c2",
   "metadata": {},
   "source": [
    "#### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a3a6e4-1c94-4ffd-bf04-157e2fa8d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved as pickle (faster for large data, preserves types)\n",
    "df.to_pickle(OUT_DIR / \"df_step03_processed.pkl\")\n",
    "study_periods.to_pickle(OUT_DIR / \"study_periods.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
