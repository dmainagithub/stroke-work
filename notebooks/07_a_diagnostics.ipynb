{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da9d05f-82e3-426b-a899-d80c3ee1f347",
   "metadata": {},
   "source": [
    "## Stroke Work\n",
    "<br>Author: Daniel Maina Nderitu<br>\n",
    "Project: MADIVA<br>\n",
    "Purpose: Diagnostics\n",
    "<br>Notes:   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbae4194-0702-4b58-92dd-6cea33139770",
   "metadata": {},
   "source": [
    "#### Bootstrap cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3630d7ff-e107-4762-85e4-8e9ab4f01d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: D:\\APHRC\\GoogleDrive_ii\\stata_do_files\\madiva\\stroke_work\n",
      "DATA_DIR: D:\\APHRC\\GoogleDrive_ii\\stata_do_files\\madiva\\stroke_work\\data\n",
      "OUT_DIR: D:\\APHRC\\GoogleDrive_ii\\stata_do_files\\madiva\\stroke_work\\model_output\n",
      "FIG_DIR: D:\\APHRC\\GoogleDrive_ii\\stata_do_files\\madiva\\stroke_work\\visualization\n"
     ]
    }
   ],
   "source": [
    "# =================== BOOTSTRAP CELL ===================\n",
    "# Standard setup for all notebooks\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parents[0]  # assumes notebooks are in a subfolder\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# ========================================================\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "\n",
    "from src.config.variables import COVARIATES\n",
    "\n",
    "# ========================================================\n",
    "# Optional for warnings and nicer plots\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ========================================================\n",
    "# 1️⃣ Ensure project root is in Python path\n",
    "# Adjust this if your notebooks are nested deeper\n",
    "PROJECT_ROOT = Path.cwd().parents[0]  # assumes notebooks are in a subfolder\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# ========================================================\n",
    "# 2️⃣ Import helper to load paths\n",
    "from src.utils.helpers import load_paths\n",
    "\n",
    "# ========================================================\n",
    "# 3️⃣ Load paths from config.yaml (works regardless of notebook location)\n",
    "paths = load_paths()\n",
    "\n",
    "# ========================================================\n",
    "# 4️⃣ Optionally, print paths to confirm\n",
    "for key, value in paths.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# ========================================================\n",
    "# 5️⃣ Now you can use these paths in your notebook:\n",
    "# Example:\n",
    "DATA_DIR = paths['DATA_DIR']\n",
    "OUT_DIR = paths['OUT_DIR']\n",
    "FIG_DIR = paths['FIG_DIR']\n",
    "\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8db072-2188-4d09-b30d-c09e8c3b99bd",
   "metadata": {},
   "source": [
    "### Import data - from previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b60d2aa-46ea-491c-8e91-224cf31f998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Loading saved data as pickle:\n",
    "# -----------------------------------------------------------------------------\n",
    "df = pd.read_pickle(OUT_DIR / \"df_step06_processed.pkl\")\n",
    "X = pd.read_pickle(OUT_DIR / \"X_step06_model_matrix.pkl\")\n",
    "y = pd.read_pickle(OUT_DIR / \"y_step06_event.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eac7f7-617d-4449-a16a-bf6f2500d541",
   "metadata": {},
   "source": [
    "#### Correlation Matrix\n",
    "Pearson correlation - gives pairwise collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5213e84c-1ea1-491d-8558-bb9aea4e37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Checking correlation matrix\n",
    "# -----------------------------------------------------------------------------\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Calculating Variance Inflation Factor (VIF) for multicollinearity\n",
    "# -----------------------------------------------------------------------------\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Checking diabetes-hypertension interaction\n",
    "# -----------------------------------------------------------------------------\n",
    "# Add interaction term\n",
    "X['hpt_diab_interaction'] = X['hpt_status_derived'] * X['diab_status_derived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f656a98-c3e2-4365-8bc9-ad035d63224a",
   "metadata": {},
   "source": [
    "#### VIF\n",
    "VIF - gives multivariate collinearity<br>\n",
    "VIF = 1 → no multicollinearity<br>\n",
    "VIF     2–5 → mild correlation<br>\n",
    "VIF > 5 (or 10) → serious multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cbfd96df-9812-4708-8f0e-d840c89f16cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VIF ANALYSIS\n",
      "============================================================\n",
      "                        Variable        VIF\n",
      "9           hpt_diab_interaction 10431.9866\n",
      "4             hpt_status_derived 10409.6072\n",
      "0                          const     7.8254\n",
      "5            diab_status_derived     3.1639\n",
      "3                    tobacco_use     1.5055\n",
      "7             hiv_status_derived     1.4873\n",
      "2                    alcohol_use     1.1595\n",
      "1                     sex_binary     1.1064\n",
      "6  bmi_category_Overweight_Obese     1.0860\n",
      "8                   site_Nairobi     1.0757\n",
      "\n",
      "\n",
      "============================================================\n",
      "CORRELATION MATRIX (Top Correlations > 0.3)\n",
      "============================================================\n",
      "hpt_status_derived    hpt_diab_interaction   0.9999\n",
      "hpt_diab_interaction  hpt_status_derived     0.9999\n",
      "diab_status_derived   hpt_diab_interaction   0.8244\n",
      "hpt_diab_interaction  diab_status_derived    0.8244\n",
      "hpt_status_derived    diab_status_derived    0.8240\n",
      "diab_status_derived   hpt_status_derived     0.8240\n",
      "tobacco_use           hiv_status_derived     0.5548\n",
      "hiv_status_derived    tobacco_use            0.5548\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# ============================================================\n",
    "# Add constant for VIF calculation (temporary)\n",
    "# -----------------------------------------------------------------------------\n",
    "X_for_vif = X.copy() if 'const' not in X.columns else X.drop('const', axis=1)\n",
    "X_for_vif = sm.add_constant(X_for_vif)\n",
    "\n",
    "# ============================================================\n",
    "# Calculate Variance Inflation Factor (VIF)\n",
    "# -----------------------------------------------------------------------------\n",
    "vif_data = pd.DataFrame()                  # Creating an empty dataframe for results\n",
    "vif_data[\"Variable\"] = X_for_vif.columns   # \n",
    "\n",
    "# ============================================================\n",
    "# The core loop\n",
    "# -----------------------------------------------------------------------------\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_for_vif.values, i) \n",
    "                   for i in range(X_for_vif.shape[1])]\n",
    "\n",
    "# ============================================================\n",
    "# Sorting by highest VIF (Most problematic at the top)\n",
    "# Which predictor is most collinear (removal or transformation)\n",
    "# -----------------------------------------------------------------------------\n",
    "vif_data = vif_data.sort_values(\"VIF\", ascending=False)   \n",
    "\n",
    "# ============================================================\n",
    "# Pearson Correlation matrix\n",
    "# -----------------------------------------------------------------------------\n",
    "corr_matrix = X.drop('const', axis=1, errors='ignore').corr()\n",
    "\n",
    "# ============================================================\n",
    "print(\"=\"*60)\n",
    "print(\"VIF ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(vif_data.to_string())\n",
    "print(\"\\n\")\n",
    "\n",
    "# ============================================================\n",
    "print(\"=\"*60)\n",
    "print(\"CORRELATION MATRIX (Top Correlations > 0.3)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================\n",
    "# Display only strong correlations\n",
    "# -----------------------------------------------------------------------------\n",
    "corr_pairs = corr_matrix.unstack()\n",
    "strong_corr = corr_pairs[(abs(corr_pairs) > 0.3) & (corr_pairs < 1)]\n",
    "if not strong_corr.empty:\n",
    "    print(strong_corr.sort_values(ascending=False))\n",
    "else:\n",
    "    print(\"No correlations > 0.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f546146-7ae5-43d5-a0d2-aa972154f0a1",
   "metadata": {},
   "source": [
    "#### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0cbaf0ad-b4ac-483f-9708-07a0d782b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved as pickle (faster for large data, preserves types)\n",
    "df.to_pickle(OUT_DIR / \"df_step07_processed.pkl\")\n",
    "X.to_pickle(OUT_DIR / \"X_step07_model_matrix.pkl\")\n",
    "y.to_pickle(OUT_DIR / \"y_step07_event.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
