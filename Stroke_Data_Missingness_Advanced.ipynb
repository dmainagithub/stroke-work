{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install missingno"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import missingno as msno\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory for saving visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: missingness_analysis_visuals\n"
     ]
    }
   ],
   "source": [
    "# Create a directory for saving visuals\n",
    "output_dir = \"missingness_analysis_visuals\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created directory: {output_dir}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {output_dir}\")\n",
    "\n",
    "# Create subdirectories for better organization\n",
    "subdirs = ['matrix', 'bar_charts', 'heatmaps', 'dendrograms', 'individual_level', 'temporal']\n",
    "for subdir in subdirs:\n",
    "    subdir_path = os.path.join(output_dir, subdir)\n",
    "    if not os.path.exists(subdir_path):\n",
    "        os.makedirs(subdir_path)\n",
    "\n",
    "# Set higher quality parameters for all plots\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['savefig.bbox'] = 'tight'\n",
    "plt.rcParams['savefig.pad_inches'] = 0.1\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_data/df_processed.csv\")\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\n",
    "    'individual_id','age', 'bmi'\n",
    "    , 'hiv_status_derived', 'hiv_status_derived_age', 'hpt_status_derived', 'hpt_status_derived_age', 'diab_status_derived', 'diab_status_derived_age',\n",
    "    'obese_status_derived', 'tb_status_derived'\n",
    "    ,'stroke_status_derived', 'stroke_status_derived_age'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Basic information\n",
    "# print(\"Dataset Shape:\", df.shape)\n",
    "# print(\"\\nFirst 5 rows:\")\n",
    "# print(df.head())\n",
    "\n",
    "# print(\"\\nData Types:\")\n",
    "# print(df.dtypes)\n",
    "\n",
    "# print(\"\\nBasic Statistics:\")\n",
    "# print(df.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Missingness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "COMPREHENSIVE MISSINGNESS ANALYSIS\n",
      "==================================================\n",
      "Total missing values: 52082\n",
      "Percentage of missing data: 8.57%\n",
      "\n",
      "Missing values by column:\n",
      "                      Missing_Count  Missing_Percentage Data_Type\n",
      "tb_status_derived             24072           51.469991   float64\n",
      "bmi                           17310           37.011696   float64\n",
      "obese_status_derived          10700           22.878402   float64\n"
     ]
    }
   ],
   "source": [
    "def comprehensive_missingness_analysis(df):\n",
    "    \"\"\"Comprehensive missing value analysis\"\"\"\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"COMPREHENSIVE MISSINGNESS ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. Overall missingness\n",
    "    total_missing = df.isnull().sum().sum()\n",
    "    total_cells = df.size\n",
    "    missing_percentage = (total_missing / total_cells) * 100\n",
    "    \n",
    "    print(f\"Total missing values: {total_missing}\")\n",
    "    print(f\"Percentage of missing data: {missing_percentage:.2f}%\")\n",
    "    \n",
    "    # 2. Missing values by column\n",
    "    missing_by_column = df.isnull().sum()\n",
    "    missing_percentage_by_column = (missing_by_column / len(df)) * 100\n",
    "    \n",
    "    print(\"\\nMissing values by column:\")\n",
    "    missing_info = pd.DataFrame({\n",
    "        'Missing_Count': missing_by_column,\n",
    "        'Missing_Percentage': missing_percentage_by_column,\n",
    "        'Data_Type': df.dtypes\n",
    "    })\n",
    "    missing_info = missing_info[missing_info['Missing_Count'] > 0]\n",
    "    \n",
    "    if len(missing_info) > 0:\n",
    "        print(missing_info.sort_values('Missing_Percentage', ascending=False))\n",
    "    else:\n",
    "        print(\"No missing values found in any column!\")\n",
    "    \n",
    "    return missing_info\n",
    "\n",
    "# Analysis\n",
    "missing_info = comprehensive_missingness_analysis(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Missing Data Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved matrix plot: missingness_matrix_full_dataset_20250826_105342.png\n",
      "Saved bar chart: missingness_barchart_full_dataset_20250826_105342.png\n",
      "Saved heatmap: missingness_heatmap_full_dataset_20250826_105342.png\n",
      "Saved dendrogram: missingness_dendrogram_full_dataset_20250826_105342.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4200x2400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x3000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4200x2400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_missingness_with_saving(df, prefix=\"\"):\n",
    "    \"\"\"Create visualizations for missing data patterns and save them\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 1. Matrix plot\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    msno.matrix(df)\n",
    "    plt.title('Missing Data Matrix Pattern', fontsize=16, pad=20)\n",
    "    plt.tight_layout()\n",
    "    filename = f\"missingness_matrix_{prefix}_{timestamp}.png\"\n",
    "    plt.savefig(os.path.join(output_dir, 'matrix', filename), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved matrix plot: {filename}\")\n",
    "    \n",
    "    # 2. Bar plot of missing values\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    missing_counts = df.isnull().sum().sort_values(ascending=False)\n",
    "    missing_counts = missing_counts[missing_counts > 0]\n",
    "    \n",
    "    if len(missing_counts) > 0:\n",
    "        ax = missing_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "        plt.title('Missing Values by Column', fontsize=16, pad=20)\n",
    "        plt.xlabel('Columns', fontsize=12)\n",
    "        plt.ylabel('Number of Missing Values', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, v in enumerate(missing_counts):\n",
    "            ax.text(i, v + 0.01 * max(missing_counts), str(v), \n",
    "                   ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        filename = f\"missingness_barchart_{prefix}_{timestamp}.png\"\n",
    "        plt.savefig(os.path.join(output_dir, 'bar_charts', filename), \n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Saved bar chart: {filename}\")\n",
    "    \n",
    "    # 3. Heatmap of missing data correlation\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    msno.heatmap(df, cmap='RdYlBu_r')\n",
    "    plt.title('Correlation of Missingness Between Variables', fontsize=16, pad=20)\n",
    "    plt.tight_layout()\n",
    "    filename = f\"missingness_heatmap_{prefix}_{timestamp}.png\"\n",
    "    plt.savefig(os.path.join(output_dir, 'heatmaps', filename), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved heatmap: {filename}\")\n",
    "    \n",
    "    # 4. Dendrogram for missing data patterns\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    msno.dendrogram(df)\n",
    "    plt.title('Dendrogram of Missing Data Patterns', fontsize=16, pad=20)\n",
    "    plt.tight_layout()\n",
    "    filename = f\"missingness_dendrogram_{prefix}_{timestamp}.png\"\n",
    "    plt.savefig(os.path.join(output_dir, 'dendrograms', filename), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved dendrogram: {filename}\")\n",
    "\n",
    "# Run the enhanced visualization\n",
    "visualize_missingness_with_saving(df, prefix=\"full_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['individual_id', 'age', 'bmi', 'hiv_status_derived',\n",
       "       'hiv_status_derived_age', 'hpt_status_derived',\n",
       "       'hpt_status_derived_age', 'diab_status_derived',\n",
       "       'diab_status_derived_age', 'obese_status_derived', 'tb_status_derived',\n",
       "       'stroke_status_derived', 'stroke_status_derived_age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Level missingness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create individual profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual_missingness_profile(df, patient_id_col='patient_id'):\n",
    "    \"\"\"\n",
    "    Create a dataframe with missingness metrics for each individual patient\n",
    "    \"\"\"\n",
    "    # Group by patient and calculate missingness metrics\n",
    "    individual_profiles = df.groupby(patient_id_col).apply(\n",
    "        lambda x: pd.Series({\n",
    "            'total_records': len(x),\n",
    "            'total_missing_values': x.isnull().sum().sum(),\n",
    "            'missing_percentage': (x.isnull().sum().sum() / (len(x) * len(x.columns))) * 100,\n",
    "            'has_stroke': x['stroke'].max() if 'stroke' in x.columns else 0,\n",
    "            'first_record_date': x['date'].min() if 'date' in x.columns else None,\n",
    "            'last_record_date': x['date'].max() if 'date' in x.columns else None,\n",
    "            'records_with_complete_data': len(x[x.isnull().sum(axis=1) == 0]),\n",
    "            'records_with_any_missing': len(x[x.isnull().sum(axis=1) > 0])\n",
    "        })\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Add column-specific missingness (example for key variables)\n",
    "    key_columns = ['age', 'bmi', 'hypertension', 'avg_glucose_level', 'smoking_status']\n",
    "    for col in key_columns:\n",
    "        if col in df.columns:\n",
    "            col_missing = df.groupby(patient_id_col)[col].apply(\n",
    "                lambda x: (x.isnull().sum() / len(x)) * 100\n",
    "            )\n",
    "            individual_profiles[f'{col}_missing_pct'] = individual_profiles[patient_id_col].map(\n",
    "                col_missing.to_dict()\n",
    "            )\n",
    "    \n",
    "    return individual_profiles\n",
    "\n",
    "# Create individual profiles - ADJUST patient_id_col IF NEEDED!\n",
    "individual_profiles = create_individual_missingness_profile(df, patient_id_col='individual_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved record count analysis: record_count_analysis_stroke_data_20250826_112456.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individual_id</th>\n",
       "      <th>total_records</th>\n",
       "      <th>total_missing_values</th>\n",
       "      <th>missing_percentage</th>\n",
       "      <th>has_stroke</th>\n",
       "      <th>first_record_date</th>\n",
       "      <th>last_record_date</th>\n",
       "      <th>records_with_complete_data</th>\n",
       "      <th>records_with_any_missing</th>\n",
       "      <th>age_missing_pct</th>\n",
       "      <th>bmi_missing_pct</th>\n",
       "      <th>record_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000025C5-5811-4942-8957-8A1A4FF1460F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2 records</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0004A623-93CA-4D53-B10C-805B27EFD98F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1 record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000D523D-F549-40B3-B8E1-2FF517084EB0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2 records</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000E6165-4313-43DE-BBFE-87581AB48FD4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.564103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3-5 records</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000EE8FA-5B5B-4917-9CF9-D15A41AF1765</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2 records</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25481</th>\n",
       "      <td>LZYHV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1 record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482</th>\n",
       "      <td>LZYMB</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2 records</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25483</th>\n",
       "      <td>LZZHL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1 record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25484</th>\n",
       "      <td>LZZOV</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2 records</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25485</th>\n",
       "      <td>LZZPO</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2 records</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25486 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              individual_id  total_records  \\\n",
       "0      000025C5-5811-4942-8957-8A1A4FF1460F            2.0   \n",
       "1      0004A623-93CA-4D53-B10C-805B27EFD98F            1.0   \n",
       "2      000D523D-F549-40B3-B8E1-2FF517084EB0            2.0   \n",
       "3      000E6165-4313-43DE-BBFE-87581AB48FD4            3.0   \n",
       "4      000EE8FA-5B5B-4917-9CF9-D15A41AF1765            2.0   \n",
       "...                                     ...            ...   \n",
       "25481                                 LZYHV            1.0   \n",
       "25482                                 LZYMB            2.0   \n",
       "25483                                 LZZHL            1.0   \n",
       "25484                                 LZZOV            2.0   \n",
       "25485                                 LZZPO            2.0   \n",
       "\n",
       "       total_missing_values  missing_percentage  has_stroke  \\\n",
       "0                       3.0           11.538462         0.0   \n",
       "1                       1.0            7.692308         0.0   \n",
       "2                       3.0           11.538462         0.0   \n",
       "3                       1.0            2.564103         0.0   \n",
       "4                       3.0           11.538462         0.0   \n",
       "...                     ...                 ...         ...   \n",
       "25481                   2.0           15.384615         0.0   \n",
       "25482                   0.0            0.000000         0.0   \n",
       "25483                   3.0           23.076923         0.0   \n",
       "25484                   1.0            3.846154         0.0   \n",
       "25485                   1.0            3.846154         0.0   \n",
       "\n",
       "       first_record_date  last_record_date  records_with_complete_data  \\\n",
       "0                    NaN               NaN                         0.0   \n",
       "1                    NaN               NaN                         0.0   \n",
       "2                    NaN               NaN                         0.0   \n",
       "3                    NaN               NaN                         2.0   \n",
       "4                    NaN               NaN                         0.0   \n",
       "...                  ...               ...                         ...   \n",
       "25481                NaN               NaN                         0.0   \n",
       "25482                NaN               NaN                         2.0   \n",
       "25483                NaN               NaN                         0.0   \n",
       "25484                NaN               NaN                         1.0   \n",
       "25485                NaN               NaN                         1.0   \n",
       "\n",
       "       records_with_any_missing  age_missing_pct  bmi_missing_pct  \\\n",
       "0                           2.0              0.0             50.0   \n",
       "1                           1.0              0.0              0.0   \n",
       "2                           2.0              0.0             50.0   \n",
       "3                           1.0              0.0              0.0   \n",
       "4                           2.0              0.0             50.0   \n",
       "...                         ...              ...              ...   \n",
       "25481                       1.0              0.0            100.0   \n",
       "25482                       0.0              0.0              0.0   \n",
       "25483                       1.0              0.0            100.0   \n",
       "25484                       1.0              0.0              0.0   \n",
       "25485                       1.0              0.0              0.0   \n",
       "\n",
       "      record_category  \n",
       "0           2 records  \n",
       "1            1 record  \n",
       "2           2 records  \n",
       "3         3-5 records  \n",
       "4           2 records  \n",
       "...               ...  \n",
       "25481        1 record  \n",
       "25482       2 records  \n",
       "25483        1 record  \n",
       "25484       2 records  \n",
       "25485       2 records  \n",
       "\n",
       "[25486 rows x 12 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_by_record_count_with_saving(individual_profiles, prefix=\"\"):\n",
    "    \"\"\"Analyze how missingness relates to number of records per patient and save visuals\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Categorize patients by number of records\n",
    "    individual_profiles['record_category'] = pd.cut(\n",
    "        individual_profiles['total_records'],\n",
    "        bins=[0, 1, 2, 5, 10, np.inf],\n",
    "        labels=['1 record', '2 records', '3-5 records', '6-10 records', '10+ records']\n",
    "    )\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Missingness by record category\n",
    "    sns.boxplot(data=individual_profiles, x='record_category', y='missing_percentage', \n",
    "                ax=ax1, palette='viridis')\n",
    "    ax1.set_title('Missing Data Percentage by Number of Records', fontsize=14, pad=15)\n",
    "    ax1.set_xlabel('Number of Records', fontsize=12)\n",
    "    ax1.set_ylabel('Missing Percentage', fontsize=12)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Stroke prevalence by record category\n",
    "    stroke_by_records = individual_profiles.groupby('record_category')['has_stroke'].mean()\n",
    "    bars = ax2.bar(range(len(stroke_by_records)), stroke_by_records.values, \n",
    "                   color='lightcoral', edgecolor='darkred', alpha=0.8)\n",
    "    ax2.set_title('Stroke Prevalence by Number of Records', fontsize=14, pad=15)\n",
    "    ax2.set_xlabel('Number of Records', fontsize=12)\n",
    "    ax2.set_ylabel('Proportion with Stroke', fontsize=12)\n",
    "    ax2.set_xticks(range(len(stroke_by_records)))\n",
    "    ax2.set_xticklabels(stroke_by_records.index, rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(stroke_by_records.values):\n",
    "        ax2.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f\"record_count_analysis_{prefix}_{timestamp}.png\"\n",
    "    plt.savefig(os.path.join(output_dir, 'individual_level', filename), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved record count analysis: {filename}\")\n",
    "    \n",
    "    return individual_profiles\n",
    "\n",
    "# Run enhanced analysis\n",
    "analyze_by_record_count_with_saving(individual_profiles, prefix=\"stroke_data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved single vs multi comparison: single_vs_multi_comparison__20250826_112658.png\n"
     ]
    }
   ],
   "source": [
    "def compare_single_vs_multi_record_with_saving(individual_profiles, prefix=\"\"):\n",
    "    \"\"\"Compare data completeness and save visuals\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    single_record = individual_profiles[individual_profiles['total_records'] == 1]\n",
    "    multi_record = individual_profiles[individual_profiles['total_records'] > 1]\n",
    "    \n",
    "    # Create comparison visualization\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Missingness comparison\n",
    "    comparison_data = pd.DataFrame({\n",
    "        'Single Record': single_record['missing_percentage'],\n",
    "        'Multiple Records': multi_record['missing_percentage']\n",
    "    })\n",
    "    \n",
    "    sns.boxplot(data=comparison_data, ax=ax1, palette='pastel')\n",
    "    ax1.set_title('Missing Data Percentage Comparison', fontsize=14, pad=15)\n",
    "    ax1.set_ylabel('Missing Percentage', fontsize=12)\n",
    "    \n",
    "    # Stroke prevalence comparison\n",
    "    stroke_single = single_record['has_stroke'].mean()\n",
    "    stroke_multi = multi_record['has_stroke'].mean()\n",
    "    \n",
    "    stroke_comparison = pd.DataFrame({\n",
    "        'Group': ['Single Record', 'Multiple Records'],\n",
    "        'Stroke Prevalence': [stroke_single, stroke_multi]\n",
    "    })\n",
    "    \n",
    "    bars = sns.barplot(data=stroke_comparison, x='Group', y='Stroke Prevalence', \n",
    "                       ax=ax2, palette='coolwarm', alpha=0.8)\n",
    "    ax2.set_title('Stroke Prevalence Comparison', fontsize=14, pad=15)\n",
    "    ax2.set_ylabel('Proportion with Stroke', fontsize=12)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate([stroke_single, stroke_multi]):\n",
    "        ax2.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    # Record count distribution\n",
    "    record_counts = [len(single_record), len(multi_record)]\n",
    "    ax3.pie(record_counts, labels=['Single Record', 'Multiple Records'], \n",
    "            autopct='%1.1f%%', colors=['lightblue', 'lightcoral'])\n",
    "    ax3.set_title('Distribution of Patients by Record Count', fontsize=14, pad=15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f\"single_vs_multi_comparison_{prefix}_{timestamp}.png\"\n",
    "    plt.savefig(os.path.join(output_dir, 'individual_level', filename), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved single vs multi comparison: {filename}\")\n",
    "    \n",
    "    return single_record, multi_record\n",
    "\n",
    "# Run enhanced comparison\n",
    "single_rec_patients, multi_rec_patients = compare_single_vs_multi_record_with_saving(individual_profiles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehensive summary (dashboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary dashboard: summary_dashboard_stroke_analysis_20250826_112923.png\n"
     ]
    }
   ],
   "source": [
    "def create_summary_dashboard(df, individual_profiles, prefix=\"\"):\n",
    "    \"\"\"Create a comprehensive summary dashboard and save it\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 16))\n",
    "    \n",
    "    # Create subplot grid\n",
    "    gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Plot 1: Overall missingness by column\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    missing_counts = df.isnull().sum().sort_values(ascending=False)\n",
    "    missing_counts = missing_counts[missing_counts > 0]\n",
    "    missing_counts.plot(kind='bar', ax=ax1, color='lightsteelblue', edgecolor='black')\n",
    "    ax1.set_title('A. Missing Values by Column', fontsize=14, pad=15)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 2: Missingness correlation heatmap\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    msno.heatmap(df, cmap='coolwarm', ax=ax2)\n",
    "    ax2.set_title('B. Missingness Correlation Heatmap', fontsize=14, pad=15)\n",
    "    \n",
    "    # Plot 3: Record count distribution\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    record_counts = individual_profiles['total_records'].value_counts().sort_index()\n",
    "    record_counts.plot(kind='bar', ax=ax3, color='lightgreen', edgecolor='black')\n",
    "    ax3.set_title('C. Distribution of Records per Patient', fontsize=14, pad=15)\n",
    "    ax3.set_xlabel('Number of Records')\n",
    "    ax3.set_ylabel('Number of Patients')\n",
    "    \n",
    "    # Plot 4: Missingness by record count\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    sns.boxplot(data=individual_profiles, x='record_category', y='missing_percentage', \n",
    "                ax=ax4, palette='viridis')\n",
    "    ax4.set_title('D. Missingness by Record Count Category', fontsize=14, pad=15)\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 5: Stroke prevalence comparison\n",
    "    ax5 = fig.add_subplot(gs[2, 0])\n",
    "    single_record = individual_profiles[individual_profiles['total_records'] == 1]\n",
    "    multi_record = individual_profiles[individual_profiles['total_records'] > 1]\n",
    "    \n",
    "    stroke_data = [single_record['has_stroke'].mean(), multi_record['has_stroke'].mean()]\n",
    "    bars = ax5.bar(['Single Record', 'Multiple Records'], stroke_data, \n",
    "                   color=['lightblue', 'lightcoral'], edgecolor='black', alpha=0.8)\n",
    "    ax5.set_title('E. Stroke Prevalence by Record Count', fontsize=14, pad=15)\n",
    "    ax5.set_ylabel('Proportion with Stroke')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(stroke_data):\n",
    "        ax5.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    # Plot 6: Text summary\n",
    "    ax6 = fig.add_subplot(gs[2, 1])\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    # Create summary text\n",
    "    summary_text = [\n",
    "        \"SUMMARY STATISTICS:\",\n",
    "        f\"Total patients: {len(individual_profiles):,}\",\n",
    "        f\"Total records: {df.shape[0]:,}\",\n",
    "        f\"Overall missingness: {df.isnull().sum().sum() / df.size * 100:.1f}%\",\n",
    "        f\"Single-record patients: {len(single_record):,} ({len(single_record)/len(individual_profiles)*100:.1f}%)\",\n",
    "        f\"Multi-record patients: {len(multi_record):,} ({len(multi_record)/len(individual_profiles)*100:.1f}%)\",\n",
    "        f\"Stroke prevalence (single): {stroke_data[0]:.3f}\",\n",
    "        f\"Stroke prevalence (multi): {stroke_data[1]:.3f}\"\n",
    "    ]\n",
    "    \n",
    "    ax6.text(0.1, 0.9, \"\\n\".join(summary_text), transform=ax6.transAxes, \n",
    "             fontsize=12, va='top', linespacing=1.5,\n",
    "             bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.7))\n",
    "    \n",
    "    plt.suptitle(f'Missingness Analysis Dashboard - Stroke Dataset\\n{timestamp}', \n",
    "                 fontsize=16, y=0.98)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = f\"summary_dashboard_{prefix}_{timestamp}.png\"\n",
    "    plt.savefig(os.path.join(output_dir, filename), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved summary dashboard: {filename}\")\n",
    "\n",
    "# Create and save the dashboard\n",
    "create_summary_dashboard(df, individual_profiles, prefix=\"stroke_analysis\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the data in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported comprehensive analysis to: missingness_analysis_visuals/missingness_analysis_report_20250826_113056.xlsx\n"
     ]
    }
   ],
   "source": [
    "def export_analysis_to_excel(df, individual_profiles, missing_info):\n",
    "    \"\"\"Export all analysis results to an Excel file with multiple sheets\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    excel_filename = f\"missingness_analysis_report_{timestamp}.xlsx\"\n",
    "    excel_path = os.path.join(output_dir, excel_filename)\n",
    "    \n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        # Raw data with missingness indicators\n",
    "        df_with_missing = df.copy()\n",
    "        for col in df.columns:\n",
    "            df_with_missing[f'{col}_missing'] = df[col].isnull().astype(int)\n",
    "        \n",
    "        df_with_missing.to_excel(writer, sheet_name='Raw_Data_With_Missing_Flags', index=False)\n",
    "        \n",
    "        # Individual profiles\n",
    "        individual_profiles.to_excel(writer, sheet_name='Individual_Profiles', index=False)\n",
    "        \n",
    "        # Missingness by column\n",
    "        missing_by_column = pd.DataFrame({\n",
    "            'column': df.columns,\n",
    "            'missing_count': df.isnull().sum(),\n",
    "            'missing_percentage': (df.isnull().sum() / len(df)) * 100,\n",
    "            'data_type': df.dtypes\n",
    "        }).sort_values('missing_percentage', ascending=False)\n",
    "        \n",
    "        missing_by_column.to_excel(writer, sheet_name='Missingness_By_Column', index=False)\n",
    "        \n",
    "        # Summary statistics\n",
    "        summary_data = {\n",
    "            'Metric': [\n",
    "                'Total Patients',\n",
    "                'Total Records', \n",
    "                'Average Records per Patient',\n",
    "                'Total Missing Values',\n",
    "                'Overall Missing Percentage',\n",
    "                'Single-record Patients',\n",
    "                'Multi-record Patients',\n",
    "                'Stroke Prevalence (Overall)',\n",
    "                'Stroke Prevalence (Single-record)',\n",
    "                'Stroke Prevalence (Multi-record)'\n",
    "            ],\n",
    "            'Value': [\n",
    "                len(individual_profiles),\n",
    "                len(df),\n",
    "                len(df) / len(individual_profiles),\n",
    "                df.isnull().sum().sum(),\n",
    "                (df.isnull().sum().sum() / df.size) * 100,\n",
    "                len(individual_profiles[individual_profiles['total_records'] == 1]),\n",
    "                len(individual_profiles[individual_profiles['total_records'] > 1]),\n",
    "                individual_profiles['has_stroke'].mean(),\n",
    "                individual_profiles[individual_profiles['total_records'] == 1]['has_stroke'].mean(),\n",
    "                individual_profiles[individual_profiles['total_records'] > 1]['has_stroke'].mean()\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        pd.DataFrame(summary_data).to_excel(writer, sheet_name='Summary_Statistics', index=False)\n",
    "    \n",
    "    print(f\"Exported comprehensive analysis to: {excel_path}\")\n",
    "    return excel_path\n",
    "\n",
    "# Export to Excel\n",
    "excel_file = export_analysis_to_excel(df, individual_profiles, missing_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stroke_status_derived\n",
      "0    44748\n",
      "1     2021\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "obese_status_derived\n",
       "0.0    25706\n",
       "1.0    10363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.stroke_status_derived.value_counts())\n",
    "df.obese_status_derived.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Missing Data Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MISSING DATA MECHANISM ANALYSIS\n",
      "==================================================\n",
      "\n",
      "Correlation of missingness in bmi with other variables:\n",
      "  age: correlation=-0.211\n",
      "  hiv_status_derived: correlation=-0.200\n",
      "  hiv_status_derived_age: correlation=-0.194\n",
      "  hpt_status_derived_age: correlation=-0.159\n",
      "  diab_status_derived_age: correlation=-0.204\n",
      "  obese_status_derived: correlation=-0.197\n",
      "  stroke_status_derived_age: correlation=-0.209\n",
      "\n",
      "Correlation of missingness in obese_status_derived with other variables:\n",
      "  age: correlation=0.110\n",
      "  bmi: correlation=-0.897\n",
      "  hiv_status_derived: correlation=0.100\n",
      "  hiv_status_derived_age: correlation=0.112\n",
      "  hpt_status_derived: correlation=0.229\n",
      "  hpt_status_derived_age: correlation=0.124\n",
      "  diab_status_derived: correlation=0.231\n",
      "  diab_status_derived_age: correlation=0.112\n",
      "  tb_status_derived: correlation=0.129\n",
      "  stroke_status_derived_age: correlation=0.110\n",
      "\n",
      "Correlation of missingness in tb_status_derived with other variables:\n",
      "  age: correlation=-0.341\n",
      "  hiv_status_derived: correlation=-0.120\n",
      "  hiv_status_derived_age: correlation=-0.319\n",
      "  hpt_status_derived: correlation=-0.129\n",
      "  hpt_status_derived_age: correlation=-0.279\n",
      "  diab_status_derived: correlation=-0.128\n",
      "  diab_status_derived_age: correlation=-0.333\n",
      "  stroke_status_derived: correlation=-0.114\n",
      "  stroke_status_derived_age: correlation=-0.338\n"
     ]
    }
   ],
   "source": [
    "def analyze_missing_mechanisms(df, target_column='stroke'):\n",
    "    \"\"\"Is missingness related to other variables\"\"\"\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"MISSING DATA MECHANISM ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Check if missingness is related to target variable (stroke)\n",
    "    for column in df.columns:\n",
    "        if df[column].isnull().sum() > 0:\n",
    "            # Indicator for missing values\n",
    "            missing_indicator = df[column].isnull().astype(int)\n",
    "            \n",
    "            if target_column in df.columns:\n",
    "                # Comparing target distribution between missing and non-missing\n",
    "                non_missing_target = df.loc[~df[column].isnull(), target_column]\n",
    "                missing_target = df.loc[df[column].isnull(), target_column]\n",
    "                \n",
    "                if len(missing_target) > 0 and len(non_missing_target) > 0:\n",
    "                    # T-test for continuous target, chi-square for categorical\n",
    "                    if df[target_column].dtype in ['int64', 'float64']:\n",
    "                        t_stat, p_value = stats.ttest_ind(\n",
    "                            non_missing_target.dropna(),\n",
    "                            missing_target.dropna(),\n",
    "                            equal_var=False\n",
    "                        )\n",
    "                        print(f\"{column}: t-stat={t_stat:.3f}, p-value={p_value:.3f}\")\n",
    "                    else:\n",
    "                        # Chi-square test (for categorical target) \n",
    "                        contingency_table = pd.crosstab(missing_indicator, df[target_column])\n",
    "                        chi2, p_value, _, _ = stats.chi2_contingency(contingency_table)\n",
    "                        print(f\"{column}: chi2={chi2:.3f}, p-value={p_value:.3f}\")\n",
    "            \n",
    "            # Correlation with other variables\n",
    "            print(f\"\\nCorrelation of missingness in {column} with other variables:\")\n",
    "            for other_col in df.columns:\n",
    "                if other_col != column and df[other_col].dtype in ['int64', 'float64']:\n",
    "                    correlation = df[other_col].corr(missing_indicator)\n",
    "                    if not pd.isna(correlation) and abs(correlation) > 0.1:\n",
    "                        print(f\"  {other_col}: correlation={correlation:.3f}\")\n",
    "\n",
    "analyze_missing_mechanisms(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Missingness Analysis for Stroke Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stroke_specific_missingness_analysis(df):\n",
    "    \"\"\"Stroke-specific missingness analysis\"\"\"\n",
    "    \n",
    "    # Analyze missingness patterns by stroke status\n",
    "    if 'stroke' in df.columns:\n",
    "        print(\"Missingness patterns by stroke status:\")\n",
    "        \n",
    "        stroke_missing = df[df['stroke'] == 1].isnull().mean() * 100\n",
    "        no_stroke_missing = df[df['stroke'] == 0].isnull().mean() * 100\n",
    "        \n",
    "        missing_comparison = pd.DataFrame({\n",
    "            'Stroke_Patients_Missing': stroke_missing,\n",
    "            'Non_Stroke_Patients_Missing': no_stroke_missing,\n",
    "            'Difference': stroke_missing - no_stroke_missing\n",
    "        })\n",
    "        \n",
    "        # Filtering columns with meaningful differences\n",
    "        meaningful_diff = missing_comparison[\n",
    "            (abs(missing_comparison['Difference']) > 2) & \n",
    "            ((stroke_missing > 5) | (no_stroke_missing > 5))\n",
    "        ]\n",
    "        \n",
    "        if len(meaningful_diff) > 0:\n",
    "            print(\"Significant differences in missingness patterns:\")\n",
    "            print(meaningful_diff.sort_values('Difference', ascending=False))\n",
    "        else:\n",
    "            print(\"No significant differences in missingness patterns between stroke and non-stroke patients\")\n",
    "\n",
    "stroke_specific_missingness_analysis(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Missingness Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missingness report saved to 'missingness_report.csv'\n",
      "\n",
      "Missingness Report Summary:\n",
      "Total rows: 46769\n",
      "Total missing values: 52082\n",
      "Overall missing percentage: 8.57%\n"
     ]
    }
   ],
   "source": [
    "def generate_missingness_report(df):\n",
    "    \"\"\"Comprehensive missingness report\"\"\"\n",
    "    \n",
    "    report = {\n",
    "        'total_rows': len(df),\n",
    "        'total_columns': len(df.columns),\n",
    "        'total_missing_values': df.isnull().sum().sum(),\n",
    "        'overall_missing_percentage': (df.isnull().sum().sum() / df.size) * 100,\n",
    "        'columns_with_missing': [],\n",
    "        'missingness_patterns': {}\n",
    "    }\n",
    "    \n",
    "    # Analyzing columns with missing values\n",
    "    for column in df.columns:\n",
    "        missing_count = df[column].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            column_info = {\n",
    "                'column_name': column,\n",
    "                'data_type': str(df[column].dtype),\n",
    "                'missing_count': missing_count,\n",
    "                'missing_percentage': (missing_count / len(df)) * 100,\n",
    "                'unique_values': df[column].nunique() if df[column].dtype == 'object' else None\n",
    "            }\n",
    "            report['columns_with_missing'].append(column_info)\n",
    "    \n",
    "    # Saving the report\n",
    "    report_df = pd.DataFrame(report['columns_with_missing'])\n",
    "    if len(report_df) > 0:\n",
    "        report_df.to_csv('stroke_output/missingness_report.csv', index=False)\n",
    "        print(\"Missingness report saved to 'missingness_report.csv'\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generating & displaying results\n",
    "missingness_report = generate_missingness_report(df)\n",
    "print(\"\\nMissingness Report Summary:\")\n",
    "print(f\"Total rows: {missingness_report['total_rows']}\")\n",
    "print(f\"Total missing values: {missingness_report['total_missing_values']}\")\n",
    "print(f\"Overall missing percentage: {missingness_report['overall_missing_percentage']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
